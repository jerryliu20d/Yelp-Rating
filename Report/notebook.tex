
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{FinalReport}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{1. Introduction}\label{introduction}

    In this project, we are going to analyse the data fetch from Yelp. Yelp
is an app that collects information about restaurants and other
business. Its recommendation system will choose the best for customers
according to history reviews. We now fetch over 1 million reviews and
over 50,000 companies information. In our project, we only focus on the
\textbf{Chinese restaurant}.

We have two main goals. Firstly, we wanted to provide some practical
advice for the business owner. On one hand, we provided suggestions
according to the business attributes. We first extracted business
attributes and sorted them according to the feature importance in Light
Gradient Boost (LGB). We discussed whether the first few attributes had
any influence on business average stars with ANOVA. On the other hand,
we analyzed customer reviews. We vectorized preprocessed words. Then
group them by 5 features (sanitation, food, waiting time, service,
price) by Cosine similarity. Then we count the frequency of each group
in each review and normalized them. Finally, we use Earth Mover Distance
to measure how these features affect the dining experience. We randomly
pick some Chinese restaurants and provide some suggestions by the
analysis above.

Secondly, we wanted to predict the reviews' star according to the review
texts. We tried many methods and finally, we choose the LSTM model. It
did a great job and our final RMSE is 0.59.

    \section{2. Data Cleaning}\label{data-cleaning}

    After extracting Chinese restaurants by searching for the word 'Chinese'
in the column 'categories' in business data, there are 3557 businesses
remained, along with 209897 reviews.

    \subsubsection{2.1 Attributes}\label{attributes}

    We split the category according to the comma. Then pick out the Chinese
restaruants. Then for other attributes, we denote all missing value like
'N/A', 'None', empty as one distinct value 'None'.

    \subsubsection{2.2 Reviews}\label{reviews}

    We preprocess the words according to the following steps: 1. Remove the
reviews that contain non-english characters 2. Splite the words
according to the white space and other punctuations 3. Change the
upper-case into lower-case 4. Expand the common abbreviation like:
wouldn't → would, not 5. Remove punctuations 6. Delete stopping words,
but keep some words like: not

    \section{3. Preliminary Analysis}\label{preliminary-analysis}

    \subsubsection{3.1 Visualization of
Attributes}\label{visualization-of-attributes}

    After data cleaning, we first looked into working times of the
restaurants. However, restaurants with different ratings apprear to have
similar average working times per week. Then barplots of average stars
in different categories for specific atttributes were drawn. Some
interesting patterns were discovered, such as average rating for dinner
restaurants tend to be high but opposite for breakfast, and noise level
also has an influence on the ratings.

The 'NoiseLevel' example: 

    \subsubsection{3.2 Visulization of
Reviews}\label{visulization-of-reviews}

    For review texts, we first drew some wordclouds (words are ordered by
appearance frequencies): Obviously, "food", "service", "time" etc were
frequently mentioned in the reviews. So we naturally took an assumption
that these are aspects that have strong impact on stars.

Secondly, we calculated word frequencies of various kinds of food in
each star and visualized them by barplots. It turned out that beef,
shrimp, crab and eggplant are the most popular ingredients and spicy is
the most popular favor. On the other hand, this indicates that food is
an important feature associated with ratings.

    \section{4. Suggestions for Business}\label{suggestions-for-business}

    \subsubsection{4.1 Attributes Analysis}\label{attributes-analysis}

    \paragraph{Missing Data}\label{missing-data}

    For the missing data, we thought they also provide some information.
Usually speaking, the missing value means the restaurant does not have
such equipment or service. For example, if they do not provide the
information about the wifi, they may not have accessible wifi. The
restaurant owner may forget to provide such information. In this
situation, this feature may not be an advantage of their service,
otherwise, they will certainly propagate it to attract customers. And
finally, the missing data may be caused by the Yelp database. But it is
not the main reason. We cannot distinguish them from others. So we can
safely ignore it. Our final decision was to denote them as specific
categories called 'None'.

    \paragraph{Light Gradient Boost}\label{light-gradient-boost}

    After preprocessing the attributes, we used Light Gradient Boost to rank
the feature importance. Light Gradient Boost is a tree-based method that
can do classification or regression. Intuitively speaking, Light
Gradient Boost will first randomly pick one feature and split the tree
nodes and then find the best split rule to minimize the regulized
objective function. Then it searches all possible features to find the
one with the minimum objective function. And the tree grows until the
improvement of the objective function does not reach the benchmark. We
repeat that process several times. And finally, we combine all leaves of
these trees together (usually we sum them up).

From the above algorithm, we can see that the Light Gradient Boost will
certainly first split node with the most important feature. And for
those features have a high correlation with the selected feature, Light
Gradient Boost may not choose them again. It provides us with a method
to rank the importance of the attributes.

Following is the barplot of importance levels for attributes: 

    \paragraph{ANOVA}\label{anova}

    Then we applied ANOVA on the selected 88 attributes. P-values, feature
importance levels, and non-missing sample sizes of attributes are
recorded in file \emph{'Tables/Attributes\_ANOVA.csv'} on github
repository. Only 5 attributes (\textbf{'Noise Level`, 'Caters`, 'HasTV`,
'Restaurants Reservations` and 'Outdoor Seating'}) passed both the
cutoff of greater or equal to 50 in importance level and less or equal
to 0.05/88=0.00057 in ANOVA p-values. So we decided to mainly focus on
these five attributes in the suggestion part.

    \subsubsection{4.2 Review Analysis}\label{review-analysis}

    In this part, We use word2vec model to vectorized the words. More
specifically, we use Skip Gram model. To introduce the Skip Gram, we
need to define the context and target word first. For each target word,
we d efine the previous and following 5 words as the context of the
target word, i.e. window\_size = 5. Then we train the Skip Gram with
target word as input and the context word as output. Generally speaking,
Skip Gram can predict the context word according to the target words.
But here we use it to find similar words.

We extract the word vectors and then use cosine similarity to find the
correlated words. The cosine similarity is defined as:
\[\frac{x*y}{\Vert x\Vert\Vert y\Vert}\] , where x, y are vectors of two
different words. We read a few reviews and search for some background
information. And finally we decided to analyze the following five
aspects: sanitation, food, waiting for time, service, price. We first
pick some words and use cosine similarity to find similar words. We
manually check the selected words and repeat that process several times.
You can find these words in the data folder.

Then we count these bag of words frequency in each review and normalized
them with word length. Then we group these data by the stars. We define
stars 1 or 2 as negative and 4 or 5 as positive. Then we use Earth
Mover's Distance (EMD) to measure the difference of the distribution of
positive and negative frequency. The reason why we did not use KL
divergence is that it will 'explode' in some situation (think of KL
divergence between N(0, \(\varepsilon^3\)) and N(\(\varepsilon\),
\(\varepsilon^3\)) when \(\varepsilon\to 0\). Also, it is not a measure
of distance (strictly speaking) because it is not symmetric. But Earth
Mover's Distance can make a remedy of it. See more details
\href{https://vincentherrmann.github.io/blog/wasserstein/}{here}. And
finally, we sort these 5 features according to the EMD and determine
whether it is an advantage or disadvantage. Then we provide some related
suggestions on it. 

    \section{5. Example Illustration}\label{example-illustration}

    We randomly pick a chinese restaraunt who has more than 20 reviews. Here
we take the restaurant 'Dragon Wok' as an example.

We first analyze its attribute. We pick the first 6 attributes according
to the feature importance from Light Gradient Boost. The Noiselevel is
average but people prefer to eat in a comparatively quiet environment.
We suggest them try to lower down the noise from the kitchen. As for the
other attributes, we thought they did well. They provide restaurant
delivery. They have caters. Alcohol is not allowed (we thought
traditional chinese food didnot taste good with wine or Liquor).

\begin{longtable}[]{@{}llllll@{}}
\toprule
- & Service & Food & Sanitation & Price & Time\tabularnewline
\midrule
\endhead
EMD & 3.72 & 3.82 & 9.34 & 10.23 & 12.20\tabularnewline
\bottomrule
\end{longtable}

\begin{verbatim}
                                    The EMD of each review feature
\end{verbatim}

Next, we analyze the reviews of this restaurant. We found that
\textbf{time} and \textbf{price} have comparatively large EMD, which
means the word frequency distribution between the positive and negative
reviews have significant difference (compare with the other review
features). However, the barplot shows that the word frequency of
positive and negative reviews have larger difference between the
\textbf{price}. As we said in chapter 4.2, EMD measure the difference
between two distribution. The \textbf{time} feature has greater EMD but
lower difference in mean value. That means the positive and negative
distribution must have some difference in the tail behavior. The
following figure shows that the distribution of the negative reviews
have heavier tail. The X-axis is the normalized word frequency for each
review. The larger x value means that the customer has stronger
positive/negative feelings. For negative reviews, we should put more
attention on the tail behavior.

\begin{verbatim}
<td>
    <img src="example1.png", width="500" height="50"> <br>
</td>
<td>
    <img src="WordFreqTime.png", width=350>
</td>
\end{verbatim}

    \section{6. Predict Review Stars}\label{predict-review-stars}

    We predict the review stars only based on the preprocessed review data.
Here we donot use the usual statistical model. Because the Natural
Language Problem (NLP) has special characteristics. The neighboring
words has strong connection. The classical classification or regression
model can not handle it well. But Long Short-Term Memory (LSTM) take the
sequence of the words into consideration! LSTM is based on Recurrent
Neural Network (RNN). Although RNN can also handle the NLP, it has a
fatal disadvantage. It cannot connect the shallower layers with the
deeper layers very well. But LSTM use 'three gates' structure to solve
this problem. The principle of LSTM is complicated. We will not discuss
the algorithm in details.

We train the model with following steps:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We first transfer the preprocessed words into integers. Each word has
  a distinct integer number.
\item
  Embed the sentences into word vectors. Each vector has length = 128,
  which is a determined hyperparameter.
\item
  Train the LSTM model with batch size = 32 and epoch = 1. And get the
  50 parameters as output.
\item
  Add Pooling Layer to filter the features out.
\item
  Use drop out layer to strength the training effect.
\item
  Add Dense layer with Rectified Linear Unit (Relu) activation function.
  It can avoid the gradient vanish problem.
\item
  Add Dense layer with linear activation function and get the predicted
  stars.
\end{enumerate}

Finally, our RMSE on test data is 0.6.

    \section{Notebook Contribution}\label{notebook-contribution}

Lijie Liu: Introduction, Preprocess, Missing Data, Light Gradient Boost,
Example Illustartion, Prediction\\
Ning Shen: ANOVA, Preliminary Analysis\\
Xiangan Zhang: Example Illustration

    \section{Code Contribution}\label{code-contribution}

Lijie Liu: Word Preprocess, Word Similarity, slides\\
Ning Shen: ANOVA, Preliminary Analysis, slides\\
Xiangan Zhang: LSTM prediction, Light Gradient Boost, EMD, slides


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
